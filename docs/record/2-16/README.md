# 2025.5.24-2025.5.30

# 科研

## APT检测存在的问题：

1. **假阳率过高（**良性样本和恶意样本之间的嵌入区分度不足，良性样本和恶意样本各自的嵌入分布不集中，共同特征没被充分挖掘**）**
2. **鲁棒性不足（存在对抗的逃逸和中毒攻击能逃避检测）**
3. **恶意标签的数据集不足**

## 目前大方向：

1. 给无监督学习加入恶意标签数据，实现**半监督（弱监督）的学习方法**，加大良性样本和恶意样本之间的嵌入区分度
2. 通过少量的标签数据，先基于规则组装数据，后续尝试使用深度学习算法，**构建攻击图生成模型**
3. 结合联邦学习

## 第一个方向

- [x]  引入恶意子图，添加对比损失增加良性节点和恶意节点的嵌入差异
- [x]  紧凑损失，使得良性节点和恶意节点的嵌入相近 (采用三元组的损失)
- [ ]  分配权重，加大困难样本（如相似的恶意节点和良性节点）的学习程度

## 以往工作

实现了了三个节点数据集上和两个图级数据集的实验，验证了第一个方向的第1点的成功结果，相对于MAGIC假阳率降低显著

选取了恶意节点10%的数据作为输入

### 实验

**MAGIC（无监督，baseline）**

![image.png](image.png)

![image.png](image%201.png)

**Slot（半监督，同样10%恶意数据）**

![image.png](image%202.png)

**Our Work**

**Trace**

![image.png](image%203.png)

**Theia**

![image.png](image%204.png)

**Cadets**

![image.png](image%205.png)

在图级数据集`streamspot`，`unicorn wget`上实验

引入紧凑损失，做实验，目前设想引入对比学习常用的的三元组损失**`Triplet loss`**

![image.png](image%206.png)

$$
L = \max \left( {d\left( {a,p}\right)  - d\left( {a,n}\right)  + \text{ margin },0}\right)
$$

这里**取间隔 (margin) 为 0。**

损失 max(0, sim_an - sim_ap) 意味着只有当**锚点-负样本的相似度 (sim_an) 严格大于锚点-正样本的相似度 (sim_ap)**时，模型才会受到惩罚（产生损失）。因为良性活动或恶意行为并不意味着他们的特征是完全紧凑的或方向是完全一致的，严格的使得两者产生margin可能对模型的泛化性能造成影响，这是我们通过实验佐证的。

## 本周工作

我们保证其他模块不变，观察修改为三元组损失后，在几个节点数据上的实验结果。

相对于以前只有单一的对比损失的优化结果，这里控制每个数据集召回率尽量一致

```yaml

theia:
	TN: 319082 -> 319109
	FN: 1
	TP: 22787
	FP: 366  -> 339

cadets:
	TN: 343270 -> 343295
	FN: 37  ->  40
	TP: 11525 -> 11522
	FP: 1057 ->  1032
	
trace:
	TN: 615980 -> 615996
	FN: 22
	TP: 61256
	FP: 41 -> 25

```

与之前做的对比损失相比，三元组损失对实验是有帮助的

## 构思文章的“故事”：

### APT检测领域假阳性率过高问题的研究现状

在高级持续性威胁（APT）检测领域，**假阳性率过高**确实是一个长期存在且亟待解决的难题。许多研究都指出了这一问题，并探讨了其产生的原因和可能的解决方案。

**良性行为的“长尾效应”与“边缘案例”**:

- **定义**: 在真实的系统环境中，存在大量罕见但完全合法的良性行为（即您所说的“数目不足的良性样本”）。这些行为可能只在特定条件下、由特定用户或特定应用程序触发，其发生频率远低于常见的良性行为。
- **影响**: 在无监督学习中，模型主要从高频、常见的良性行为中学习“正常”模式。当这些罕见的良性行为出现时，由于其模式与已学习到的“主流正常”模式差异较大，很容易被模型误判为异常（即假阳性）。它们在特征空间中可能确实与其他“主流”良性样本的相似度较低。
- **具体例子**:
    - **系统管理员的维护操作**: 系统管理员可能会执行一些不常见的命令行操作、使用特殊的系统工具或修改敏感的系统配置。这些操作对于普通用户来说是异常的，但对于管理员是完全正常的。如果数据集中这类操作的样本不足，模型就很难学会将它们识别为良性。
    - **特定业务应用的罕见功能**: 某个企业内部应用的某个不常用但合法的功能（例如，月底生成一份特殊的汇总报告，涉及大量文件读取和计算），其行为模式可能与日常操作显著不同。

**“正常”边界的模糊性与动态性**:

- **定义**: “什么是正常的”这个概念本身就不是一成不变的，它会随着系统更新、软件部署、用户习惯的改变而动态变化。
- **影响**: 无监督模型学习到的“正常”边界如果不够灵活或泛化能力不足，就很难适应这种动态性。过去正常的行为，在系统升级后可能因为日志模式的微小改变而被误判。新的、合法的应用程序引入也可能产生新的、未被学习过的良性行为模式。
- **具体例子**:
    - **操作系统或大型应用更新**: 更新后，某些系统进程的行为、日志格式或API调用序列可能发生变化，导致模型将这些新的正常行为识别为异常。

主流的APT检测算法面临以下挑战：

- **学习效果差**: 模型对“正常”的定义会过于狭隘，主要基于常见的良性行为。
- **与其他良性样本在特征空间中相似度过低**: 当这些罕见的良性行为发生时，它们在模型构建的特征空间中可能会远离那些“主流”的良性样本簇，因为模型没有学习到它们与主流良性行为之间的潜在关联或将它们视为同一“正常”概念下的变体。
- **被误判为异常（高假阳性）**: 由于这些罕见的良性样本在特征空间中显得“格格不入”，任何基于距离、密度或重构误差的无监督异常检测算法都很容易将它们标记为异常，从而产生假阳性。

因此，我们考虑引入恶意样本，并且采用双重聚焦选择合适的三元组进行在嵌入表示中做有监督的对比学习，应对目前无监督学习面临的挑战。我们希望找到与恶性样本相似嵌入的那些良性嵌入，还有那些难以学习的良性嵌入。

### 目标唯一，双重聚焦

1. **第一重聚焦：**通过批处理困难样本挖掘**，自动、隐式地聚焦于那些在几何上**最接近恶意节点的“困难”良性样本。这直接实现了“加强与恶意节点相近的良性节点学习”的需求，且无需计算额外的权重。
2. **第二重聚焦**：通过**GMAE-VIB 混合编码器，**提供的`μ`嵌入用于稳定的重建，`σ`用于鲁棒的采样，而计算得到的每一个节点的`KL散度`，即每个节点的“`编码代价`”，能**对那些在**信息论上更复杂、更罕见的“困难”良性样本，进行一次显式的、额外的加权。

重点在第二重聚焦，用自监督的方式评估良性样本的内在困难度，然后用这个困难度指导有监督的良恶性边界学习。

  

同时后期可以加入**信息瓶颈正则项，**将所有良性节点的平均KL散度作为正则项，确保编码器整体上致力于信息压缩，学习最本质的特征。

## 计划

1. 完成目前的设想，并做实验
2. 开始编写论文的绪论
3. 寻找新数据做实验，Flash有一个`Drapa Optc`的`groundtruth`，应该可以作为补充数据集